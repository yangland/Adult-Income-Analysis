{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b2927f-a8a4-4cfb-87c0-63345a148a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:19:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">527</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m23\u001b[0m \u001b[1;92m21:19:00\u001b[0m,\u001b[1;36m527\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m140\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:19:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">622</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m23\u001b[0m \u001b[1;92m21:19:00\u001b[0m,\u001b[1;36m622\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m524\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:19:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">626</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:499</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m23\u001b[0m \u001b[1;92m21:19:00\u001b[0m,\u001b[1;36m626\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:499\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:19:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">660</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">574</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m23\u001b[0m \u001b[1;92m21:19:00\u001b[0m,\u001b[1;36m660\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m574\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:19:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">717</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m23\u001b[0m \u001b[1;92m21:19:00\u001b[0m,\u001b[1;36m717\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:19:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">171</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">630</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m23\u001b[0m \u001b[1;92m21:19:02\u001b[0m,\u001b[1;36m171\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m630\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\py310\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:639: Checkpoint directory D:\\GitHub\\Adult-Income-Analysis\\saved_models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "D:\\anaconda3\\envs\\py310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "D:\\anaconda3\\envs\\py310\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "D:\\anaconda3\\envs\\py310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba211dda27d04e9aab633e89c6a5a216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 91 steps due to diverging loss.\n",
      "Learning rate set to 0.00017378008287493763\n",
      "Restoring states from the checkpoint path at D:\\GitHub\\Adult-Income-Analysis\\.lr_find_372332ee-c05d-4e0a-b941-91c31db08684.ckpt\n",
      "Restored all states from the checkpoint at D:\\GitHub\\Adult-Income-Analysis\\.lr_find_372332ee-c05d-4e0a-b941-91c31db08684.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:19:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">138</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">643</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00017378008287493763</span>. For   \n",
       "plot and detailed analysis, use `find_learning_rate` method.                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m23\u001b[0m \u001b[1;92m21:19:45\u001b[0m,\u001b[1;36m138\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m643\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.00017378008287493763\u001b[0m. For   \n",
       "plot and detailed analysis, use `find_learning_rate` method.                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:19:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">144</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">652</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m23\u001b[0m \u001b[1;92m21:19:45\u001b[0m,\u001b[1;36m144\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m652\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  817 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │     92 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │  1.0 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss          │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  817 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │     92 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │  1.0 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss          │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 818 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 818 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 3                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 818 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 818 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 3                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30790728bc6b4caa92abd64638b5227b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:19:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">249</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">663</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m23\u001b[0m \u001b[1;92m21:19:46\u001b[0m,\u001b[1;36m249\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m663\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:19:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">251</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1489</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m23\u001b[0m \u001b[1;92m21:19:46\u001b[0m,\u001b[1;36m251\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1489\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b98f5dac1174084b92d6efdadc69f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4399999976158142     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6946454644203186     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4399999976158142    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6946454644203186    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\py310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install torch torchvision torchaudio\n",
    "# !pip install pytorch_tabular[all]\n",
    "\n",
    "## Prepare utility functions\n",
    "from sklearn.datasets import make_classification\n",
    "def make_mixed_classification(n_samples, n_features, n_categories):\n",
    "    X,y = make_classification(n_samples=n_samples, n_features=n_features, random_state=42, n_informative=5)\n",
    "    cat_cols = random.choices(list(range(X.shape[-1])),k=n_categories)\n",
    "    num_cols = [i for i in range(X.shape[-1]) if i not in cat_cols]\n",
    "    for col in cat_cols:\n",
    "        X[:,col] = pd.qcut(X[:,col], q=4).codes.astype(int)\n",
    "    col_names = [] \n",
    "    num_col_names=[]\n",
    "    cat_col_names=[]\n",
    "    for i in range(X.shape[-1]):\n",
    "        if i in cat_cols:\n",
    "            col_names.append(f\"cat_col_{i}\")\n",
    "            cat_col_names.append(f\"cat_col_{i}\")\n",
    "        if i in num_cols:\n",
    "            col_names.append(f\"num_col_{i}\")\n",
    "            num_col_names.append(f\"num_col_{i}\")\n",
    "    X = pd.DataFrame(X, columns=col_names)\n",
    "    y = pd.Series(y, name=\"target\")\n",
    "    data = X.join(y)\n",
    "    return data, cat_col_names, num_col_names\n",
    "\n",
    "## Obtain trainign data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "data, cat_col_names, num_col_names = make_mixed_classification(n_samples=100, n_features=20, n_categories=4)\n",
    "train, test = train_test_split(data, random_state=42)\n",
    "train, val = train_test_split(train, random_state=42)\n",
    "\n",
    "## Define a machine learning model using Pytorch Tabular\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=['target'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100,\n",
    "    devices=1, #index of the GPU to use. 0, means CPU\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"1024-512-512\",  # Number of nodes in each layer\n",
    "    activation=\"LeakyReLU\", # Activation between each layers\n",
    "    learning_rate = 1e-2\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "## Start learning\n",
    "# see https://stackoverflow.com/questions/43769068/jupyter-notebook-widget-javascript-not-detected if error occurs\n",
    "tabular_model.fit(train=train, validation=val)\n",
    "result = tabular_model.evaluate(test)\n",
    "pred_df = tabular_model.predict(test)\n",
    "tabular_model.save_model(\"examples/basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db2ef98-abd6-468b-8a77-ab39ed91a528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6946454644203186, 'test_accuracy': 0.4399999976158142}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e3ce138-d4b5-4e1d-aae8-5ea9df197e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col_0</th>\n",
       "      <th>num_col_1</th>\n",
       "      <th>num_col_2</th>\n",
       "      <th>cat_col_3</th>\n",
       "      <th>num_col_4</th>\n",
       "      <th>num_col_5</th>\n",
       "      <th>num_col_6</th>\n",
       "      <th>num_col_7</th>\n",
       "      <th>num_col_8</th>\n",
       "      <th>num_col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>num_col_11</th>\n",
       "      <th>num_col_12</th>\n",
       "      <th>num_col_13</th>\n",
       "      <th>cat_col_14</th>\n",
       "      <th>cat_col_15</th>\n",
       "      <th>num_col_16</th>\n",
       "      <th>num_col_17</th>\n",
       "      <th>num_col_18</th>\n",
       "      <th>cat_col_19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074206</td>\n",
       "      <td>0.269669</td>\n",
       "      <td>0.722540</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.222833</td>\n",
       "      <td>0.950503</td>\n",
       "      <td>-0.028925</td>\n",
       "      <td>0.736467</td>\n",
       "      <td>1.176131</td>\n",
       "      <td>-0.229403</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810924</td>\n",
       "      <td>1.308912</td>\n",
       "      <td>-0.342976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.079385</td>\n",
       "      <td>0.707716</td>\n",
       "      <td>0.505502</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.014419</td>\n",
       "      <td>0.424234</td>\n",
       "      <td>0.611144</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.379947</td>\n",
       "      <td>-0.965498</td>\n",
       "      <td>-2.402754</td>\n",
       "      <td>-3.518210</td>\n",
       "      <td>1.001620</td>\n",
       "      <td>0.782870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306700</td>\n",
       "      <td>-1.047075</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.095497</td>\n",
       "      <td>1.479079</td>\n",
       "      <td>-0.256588</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.249096</td>\n",
       "      <td>-1.156744</td>\n",
       "      <td>-1.824070</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.363878</td>\n",
       "      <td>0.059142</td>\n",
       "      <td>-0.019935</td>\n",
       "      <td>-1.016913</td>\n",
       "      <td>1.395276</td>\n",
       "      <td>-0.682992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057784</td>\n",
       "      <td>2.650452</td>\n",
       "      <td>1.126117</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.304660</td>\n",
       "      <td>1.445385</td>\n",
       "      <td>-0.454244</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.641931</td>\n",
       "      <td>-0.352013</td>\n",
       "      <td>2.105202</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.856569</td>\n",
       "      <td>2.687534</td>\n",
       "      <td>1.474056</td>\n",
       "      <td>-0.795152</td>\n",
       "      <td>-0.175284</td>\n",
       "      <td>0.653283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295619</td>\n",
       "      <td>-0.472407</td>\n",
       "      <td>-1.810032</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.584861</td>\n",
       "      <td>0.230010</td>\n",
       "      <td>-0.687934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.940414</td>\n",
       "      <td>-0.937356</td>\n",
       "      <td>-1.241501</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.247805</td>\n",
       "      <td>0.252756</td>\n",
       "      <td>-0.657233</td>\n",
       "      <td>2.088315</td>\n",
       "      <td>-2.797189</td>\n",
       "      <td>0.234652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.486723</td>\n",
       "      <td>0.135038</td>\n",
       "      <td>1.646397</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.138604</td>\n",
       "      <td>1.764687</td>\n",
       "      <td>-1.007089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col_0  num_col_1  num_col_2  cat_col_3  num_col_4  num_col_5  \\\n",
       "0   0.074206   0.269669   0.722540        2.0   0.222833   0.950503   \n",
       "1  -1.014419   0.424234   0.611144        2.0   0.379947  -0.965498   \n",
       "2  -2.249096  -1.156744  -1.824070        3.0   0.363878   0.059142   \n",
       "3   0.641931  -0.352013   2.105202        3.0  -1.856569   2.687534   \n",
       "4  -0.940414  -0.937356  -1.241501        3.0  -1.247805   0.252756   \n",
       "\n",
       "   num_col_6  num_col_7  num_col_8  num_col_9  ...  num_col_11  num_col_12  \\\n",
       "0  -0.028925   0.736467   1.176131  -0.229403  ...   -0.810924    1.308912   \n",
       "1  -2.402754  -3.518210   1.001620   0.782870  ...   -0.306700   -1.047075   \n",
       "2  -0.019935  -1.016913   1.395276  -0.682992  ...   -0.057784    2.650452   \n",
       "3   1.474056  -0.795152  -0.175284   0.653283  ...    0.295619   -0.472407   \n",
       "4  -0.657233   2.088315  -2.797189   0.234652  ...    1.486723    0.135038   \n",
       "\n",
       "   num_col_13  cat_col_14  cat_col_15  num_col_16  num_col_17  num_col_18  \\\n",
       "0   -0.342976         0.0         1.0   -0.079385    0.707716    0.505502   \n",
       "1    0.030162         3.0         2.0    0.095497    1.479079   -0.256588   \n",
       "2    1.126117         3.0         0.0    2.304660    1.445385   -0.454244   \n",
       "3   -1.810032         2.0         3.0    0.584861    0.230010   -0.687934   \n",
       "4    1.646397         3.0         0.0    1.138604    1.764687   -1.007089   \n",
       "\n",
       "   cat_col_19  target  \n",
       "0         2.0       1  \n",
       "1         3.0       1  \n",
       "2         3.0       1  \n",
       "3         0.0       1  \n",
       "4         0.0       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fada67c-8134-4a7a-998b-d22d4b0513bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col_0</th>\n",
       "      <th>num_col_1</th>\n",
       "      <th>num_col_2</th>\n",
       "      <th>cat_col_3</th>\n",
       "      <th>num_col_4</th>\n",
       "      <th>num_col_5</th>\n",
       "      <th>num_col_6</th>\n",
       "      <th>num_col_7</th>\n",
       "      <th>num_col_8</th>\n",
       "      <th>num_col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>num_col_11</th>\n",
       "      <th>num_col_12</th>\n",
       "      <th>num_col_13</th>\n",
       "      <th>cat_col_14</th>\n",
       "      <th>cat_col_15</th>\n",
       "      <th>num_col_16</th>\n",
       "      <th>num_col_17</th>\n",
       "      <th>num_col_18</th>\n",
       "      <th>cat_col_19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.805372</td>\n",
       "      <td>-0.303662</td>\n",
       "      <td>1.305970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.574877</td>\n",
       "      <td>0.270975</td>\n",
       "      <td>0.350785</td>\n",
       "      <td>-2.566409</td>\n",
       "      <td>1.095867</td>\n",
       "      <td>0.596442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.757797</td>\n",
       "      <td>-0.383026</td>\n",
       "      <td>0.304193</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306238</td>\n",
       "      <td>-0.165399</td>\n",
       "      <td>1.807876</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.994106</td>\n",
       "      <td>1.168218</td>\n",
       "      <td>-0.444946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.710398</td>\n",
       "      <td>-1.960158</td>\n",
       "      <td>-0.040089</td>\n",
       "      <td>-0.732537</td>\n",
       "      <td>-0.242779</td>\n",
       "      <td>-0.030939</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.181683</td>\n",
       "      <td>-1.749469</td>\n",
       "      <td>2.060559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.897121</td>\n",
       "      <td>-2.302697</td>\n",
       "      <td>-1.193060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.164698</td>\n",
       "      <td>0.104735</td>\n",
       "      <td>0.884101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.805801</td>\n",
       "      <td>0.583800</td>\n",
       "      <td>-0.850556</td>\n",
       "      <td>1.537580</td>\n",
       "      <td>-2.416135</td>\n",
       "      <td>-0.362535</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386351</td>\n",
       "      <td>1.255611</td>\n",
       "      <td>0.543499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.739014</td>\n",
       "      <td>-1.257340</td>\n",
       "      <td>1.083610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.033459</td>\n",
       "      <td>2.117856</td>\n",
       "      <td>0.694998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.407292</td>\n",
       "      <td>0.701373</td>\n",
       "      <td>0.462626</td>\n",
       "      <td>0.362770</td>\n",
       "      <td>-0.501750</td>\n",
       "      <td>-0.621818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537050</td>\n",
       "      <td>1.399536</td>\n",
       "      <td>1.031063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.620539</td>\n",
       "      <td>-1.233468</td>\n",
       "      <td>0.108543</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.075144</td>\n",
       "      <td>0.383972</td>\n",
       "      <td>0.499637</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.052837</td>\n",
       "      <td>0.063688</td>\n",
       "      <td>1.206153</td>\n",
       "      <td>2.934273</td>\n",
       "      <td>-5.518044</td>\n",
       "      <td>-0.578963</td>\n",
       "      <td>...</td>\n",
       "      <td>5.578709</td>\n",
       "      <td>-1.131236</td>\n",
       "      <td>0.471961</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.656914</td>\n",
       "      <td>0.401192</td>\n",
       "      <td>0.139215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_col_0  num_col_1  num_col_2  cat_col_3  num_col_4  num_col_5  \\\n",
       "74  -0.805372  -0.303662   1.305970        0.0  -1.574877   0.270975   \n",
       "50  -0.994106   1.168218  -0.444946        0.0  -0.710398  -1.960158   \n",
       "67   0.164698   0.104735   0.884101        0.0   0.805801   0.583800   \n",
       "34   0.033459   2.117856   0.694998        1.0  -0.407292   0.701373   \n",
       "97  -0.075144   0.383972   0.499637        3.0   2.052837   0.063688   \n",
       "\n",
       "    num_col_6  num_col_7  num_col_8  num_col_9  ...  num_col_11  num_col_12  \\\n",
       "74   0.350785  -2.566409   1.095867   0.596442  ...   -0.757797   -0.383026   \n",
       "50  -0.040089  -0.732537  -0.242779  -0.030939  ...   -1.181683   -1.749469   \n",
       "67  -0.850556   1.537580  -2.416135  -0.362535  ...    1.386351    1.255611   \n",
       "34   0.462626   0.362770  -0.501750  -0.621818  ...    0.537050    1.399536   \n",
       "97   1.206153   2.934273  -5.518044  -0.578963  ...    5.578709   -1.131236   \n",
       "\n",
       "    num_col_13  cat_col_14  cat_col_15  num_col_16  num_col_17  num_col_18  \\\n",
       "74    0.304193         2.0         0.0    0.306238   -0.165399    1.807876   \n",
       "50    2.060559         0.0         0.0   -1.897121   -2.302697   -1.193060   \n",
       "67    0.543499         0.0         0.0    1.739014   -1.257340    1.083610   \n",
       "34    1.031063         0.0         0.0    1.620539   -1.233468    0.108543   \n",
       "97    0.471961         3.0         1.0    2.656914    0.401192    0.139215   \n",
       "\n",
       "    cat_col_19  target  \n",
       "74         1.0       1  \n",
       "50         0.0       0  \n",
       "67         0.0       0  \n",
       "34         3.0       1  \n",
       "97         0.0       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f5cec8f-5489-48dc-93b8-857db78c5206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col_0</th>\n",
       "      <th>num_col_1</th>\n",
       "      <th>num_col_2</th>\n",
       "      <th>cat_col_3</th>\n",
       "      <th>num_col_4</th>\n",
       "      <th>num_col_5</th>\n",
       "      <th>num_col_6</th>\n",
       "      <th>num_col_7</th>\n",
       "      <th>num_col_8</th>\n",
       "      <th>num_col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>num_col_11</th>\n",
       "      <th>num_col_12</th>\n",
       "      <th>num_col_13</th>\n",
       "      <th>cat_col_14</th>\n",
       "      <th>cat_col_15</th>\n",
       "      <th>num_col_16</th>\n",
       "      <th>num_col_17</th>\n",
       "      <th>num_col_18</th>\n",
       "      <th>cat_col_19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.480146</td>\n",
       "      <td>-0.886220</td>\n",
       "      <td>-2.162219</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.729718</td>\n",
       "      <td>0.377351</td>\n",
       "      <td>-0.194332</td>\n",
       "      <td>-2.613506</td>\n",
       "      <td>0.566719</td>\n",
       "      <td>2.730867</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.892458</td>\n",
       "      <td>-2.130572</td>\n",
       "      <td>-0.180490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.427480</td>\n",
       "      <td>0.103544</td>\n",
       "      <td>-0.779152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.073770</td>\n",
       "      <td>0.602477</td>\n",
       "      <td>1.161934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.954635</td>\n",
       "      <td>0.057013</td>\n",
       "      <td>-0.628485</td>\n",
       "      <td>-0.708539</td>\n",
       "      <td>-0.295064</td>\n",
       "      <td>1.397226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819933</td>\n",
       "      <td>0.171998</td>\n",
       "      <td>-0.647241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.541361</td>\n",
       "      <td>-0.510436</td>\n",
       "      <td>-0.058882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.125847</td>\n",
       "      <td>0.834233</td>\n",
       "      <td>-0.966312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.557920</td>\n",
       "      <td>-1.316749</td>\n",
       "      <td>-1.212090</td>\n",
       "      <td>-0.725942</td>\n",
       "      <td>-0.744303</td>\n",
       "      <td>1.028683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262295</td>\n",
       "      <td>-1.249062</td>\n",
       "      <td>0.723611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.945760</td>\n",
       "      <td>0.650382</td>\n",
       "      <td>0.667461</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.956440</td>\n",
       "      <td>-0.649266</td>\n",
       "      <td>-2.773563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.143736</td>\n",
       "      <td>0.827850</td>\n",
       "      <td>1.115902</td>\n",
       "      <td>2.466316</td>\n",
       "      <td>-3.396234</td>\n",
       "      <td>-0.624790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654254</td>\n",
       "      <td>-1.821179</td>\n",
       "      <td>-0.007043</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.815159</td>\n",
       "      <td>0.682034</td>\n",
       "      <td>1.312409</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-0.158101</td>\n",
       "      <td>-1.434365</td>\n",
       "      <td>-0.798439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.416953</td>\n",
       "      <td>0.383614</td>\n",
       "      <td>0.198558</td>\n",
       "      <td>1.084541</td>\n",
       "      <td>-1.579066</td>\n",
       "      <td>0.806593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527332</td>\n",
       "      <td>1.767058</td>\n",
       "      <td>-2.369721</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.232166</td>\n",
       "      <td>-1.524015</td>\n",
       "      <td>-0.348013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_col_0  num_col_1  num_col_2  cat_col_3  num_col_4  num_col_5  \\\n",
       "72   0.480146  -0.886220  -2.162219        3.0   0.729718   0.377351   \n",
       "23   0.073770   0.602477   1.161934        0.0  -1.954635   0.057013   \n",
       "5    0.125847   0.834233  -0.966312        0.0   0.557920  -1.316749   \n",
       "15   0.956440  -0.649266  -2.773563        1.0  -3.143736   0.827850   \n",
       "56  -0.158101  -1.434365  -0.798439        0.0  -2.416953   0.383614   \n",
       "\n",
       "    num_col_6  num_col_7  num_col_8  num_col_9  ...  num_col_11  num_col_12  \\\n",
       "72  -0.194332  -2.613506   0.566719   2.730867  ...   -1.892458   -2.130572   \n",
       "23  -0.628485  -0.708539  -0.295064   1.397226  ...    0.819933    0.171998   \n",
       "5   -1.212090  -0.725942  -0.744303   1.028683  ...   -0.262295   -1.249062   \n",
       "15   1.115902   2.466316  -3.396234  -0.624790  ...    0.654254   -1.821179   \n",
       "56   0.198558   1.084541  -1.579066   0.806593  ...    0.527332    1.767058   \n",
       "\n",
       "    num_col_13  cat_col_14  cat_col_15  num_col_16  num_col_17  num_col_18  \\\n",
       "72   -0.180490         1.0         2.0   -2.427480    0.103544   -0.779152   \n",
       "23   -0.647241         0.0         1.0    1.541361   -0.510436   -0.058882   \n",
       "5     0.723611         0.0         2.0   -0.945760    0.650382    0.667461   \n",
       "15   -0.007043         3.0         3.0   -0.815159    0.682034    1.312409   \n",
       "56   -2.369721         2.0         3.0    2.232166   -1.524015   -0.348013   \n",
       "\n",
       "    cat_col_19  target  \n",
       "72         1.0       1  \n",
       "23         0.0       1  \n",
       "5          2.0       1  \n",
       "15         2.0       0  \n",
       "56         3.0       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e857f9-12a1-4473-a7d9-b9f5aa5844a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
