{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult = pd.read_csv('adult.csv')\n",
    "\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num','marital-status', 'occupation', 'relationship', 'race', 'gender','capital-gain', 'capital-loss', 'hours-per-week', 'native-country','income']\n",
    "\n",
    "train = pd.read_csv('adult_data.txt', sep=\",\\s\", header=None, names = column_names, engine = 'python')\n",
    "test = pd.read_csv('adult_test.txt', sep=\",\\s\", header=None, names = column_names, engine = 'python')\n",
    "test['income'].replace(regex=True,inplace=True,to_replace=r'\\.',value=r'')\n",
    "\n",
    "\n",
    "adult = pd.concat([test,train])\n",
    "adult.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 1.1. Columns and their types"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   age              48842 non-null  int64   \n",
      " 1   workclass        48842 non-null  category\n",
      " 2   fnlwgt           48842 non-null  int64   \n",
      " 3   education        48842 non-null  category\n",
      " 4   educational-num  48842 non-null  int64   \n",
      " 5   marital-status   48842 non-null  category\n",
      " 6   occupation       48842 non-null  category\n",
      " 7   relationship     48842 non-null  category\n",
      " 8   race             48842 non-null  category\n",
      " 9   gender           48842 non-null  category\n",
      " 10  capital-gain     48842 non-null  int64   \n",
      " 11  capital-loss     48842 non-null  int64   \n",
      " 12  hours-per-week   48842 non-null  int64   \n",
      " 13  native-country   48842 non-null  category\n",
      " 14  income           48842 non-null  category\n",
      "dtypes: category(9), int64(6)\n",
      "memory usage: 2.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Setting all the categorical columns to type category\n",
    "for col in set(adult.columns) - set(adult.describe().columns):\n",
    "    adult[col] = adult[col].astype('category')\n",
    "    \n",
    "printmd('## 1.1. Columns and their types')\n",
    "print(adult.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 1.2. Data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 records\n",
    "printmd('## 1.2. Data')\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 1.3. Summary Statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  educational-num  capital-gain  \\\n",
       "count  48842.000000  4.884200e+04     48842.000000  48842.000000   \n",
       "mean      38.643585  1.896641e+05        10.078089   1079.067626   \n",
       "std       13.710510  1.056040e+05         2.570973   7452.019058   \n",
       "min       17.000000  1.228500e+04         1.000000      0.000000   \n",
       "25%       28.000000  1.175505e+05         9.000000      0.000000   \n",
       "50%       37.000000  1.781445e+05        10.000000      0.000000   \n",
       "75%       48.000000  2.376420e+05        12.000000      0.000000   \n",
       "max       90.000000  1.490400e+06        16.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week  \n",
       "count  48842.000000    48842.000000  \n",
       "mean      87.502314       40.422382  \n",
       "std      403.004552       12.391444  \n",
       "min        0.000000        1.000000  \n",
       "25%        0.000000       40.000000  \n",
       "50%        0.000000       40.000000  \n",
       "75%        0.000000       45.000000  \n",
       "max     4356.000000       99.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('## 1.3. Summary Statistics')\n",
    "\n",
    "adult.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 1.4. Missing values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "workclass: 2799 records"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "occupation: 2809 records"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "native-country: 857 records"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('## 1.4. Missing values')\n",
    "for i,j in zip(adult.columns,(adult.values.astype(str) == '?').sum(axis = 0)):\n",
    "    if j > 0:\n",
    "        printmd(str(i) + ': ' + str(j) + ' records')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Remove \"?\" value records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_pred = adult.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt   education  educational-num      marital-status  \\\n",
       "0   25    Private  226802        11th                7       Never-married   \n",
       "1   38    Private   89814     HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951  Assoc-acdm               12  Married-civ-spouse   \n",
       "\n",
       "          occupation relationship   race gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black   Male             0             0   \n",
       "1    Farming-fishing      Husband  White   Male             0             0   \n",
       "2    Protective-serv      Husband  White   Male             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_pred.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one hot encoding of the categorical columns in the data frame.\n",
    "def oneHotCatVars(df, df_cols):\n",
    "    \n",
    "    df_1 = adult_data = df.drop(columns = df_cols, axis = 1)\n",
    "    df_2 = pd.get_dummies(df[df_cols])\n",
    "    \n",
    "    return (pd.concat([df_1, df_2], axis=1, join='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep\n",
    "adult_data = adult_pred.drop(columns = ['income'])\n",
    "adult_label = adult_pred.income\n",
    "\n",
    "adult_label = adult_label.replace(\"<=50K\", 0)\n",
    "adult_label = adult_label.replace(\">50K\", 1)\n",
    "\n",
    "adult_cat_1hot = pd.get_dummies(adult_data.select_dtypes('category'))\n",
    "adult_non_cat = adult_data.select_dtypes(exclude = 'category')\n",
    "\n",
    "adult_data_1hot = pd.concat([adult_non_cat, adult_cat_1hot], axis=1, join='inner')\n",
    "adult_data_1hot = adult_data_1hot.replace(False, 0)\n",
    "adult_data_1hot = adult_data_1hot.replace(True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>226802</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>89814</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>336951</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>160323</td>\n",
       "      <td>10</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>198693</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>257302</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>154374</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>151910</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>201490</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>287927</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  educational-num  capital-gain  capital-loss  \\\n",
       "0       25  226802                7             0             0   \n",
       "1       38   89814                9             0             0   \n",
       "2       28  336951               12             0             0   \n",
       "3       44  160323               10          7688             0   \n",
       "5       34  198693                6             0             0   \n",
       "...    ...     ...              ...           ...           ...   \n",
       "48837   27  257302               12             0             0   \n",
       "48838   40  154374                9             0             0   \n",
       "48839   58  151910                9             0             0   \n",
       "48840   22  201490                9             0             0   \n",
       "48841   52  287927                9         15024             0   \n",
       "\n",
       "       hours-per-week  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "0                  40                      0                    0   \n",
       "1                  50                      0                    0   \n",
       "2                  40                      0                    1   \n",
       "3                  40                      0                    0   \n",
       "5                  30                      0                    0   \n",
       "...               ...                    ...                  ...   \n",
       "48837              38                      0                    0   \n",
       "48838              40                      0                    0   \n",
       "48839              40                      0                    0   \n",
       "48840              20                      0                    0   \n",
       "48841              40                      0                    0   \n",
       "\n",
       "       workclass_Never-worked  workclass_Private  ...  \\\n",
       "0                           0                  1  ...   \n",
       "1                           0                  1  ...   \n",
       "2                           0                  0  ...   \n",
       "3                           0                  1  ...   \n",
       "5                           0                  1  ...   \n",
       "...                       ...                ...  ...   \n",
       "48837                       0                  1  ...   \n",
       "48838                       0                  1  ...   \n",
       "48839                       0                  1  ...   \n",
       "48840                       0                  1  ...   \n",
       "48841                       0                  0  ...   \n",
       "\n",
       "       native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "5                            0                           0   \n",
       "...                        ...                         ...   \n",
       "48837                        0                           0   \n",
       "48838                        0                           0   \n",
       "48839                        0                           0   \n",
       "48840                        0                           0   \n",
       "48841                        0                           0   \n",
       "\n",
       "       native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "0                            0                     0                      0   \n",
       "1                            0                     0                      0   \n",
       "2                            0                     0                      0   \n",
       "3                            0                     0                      0   \n",
       "5                            0                     0                      0   \n",
       "...                        ...                   ...                    ...   \n",
       "48837                        0                     0                      0   \n",
       "48838                        0                     0                      0   \n",
       "48839                        0                     0                      0   \n",
       "48840                        0                     0                      0   \n",
       "48841                        0                     0                      0   \n",
       "\n",
       "       native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "0                            0                               0   \n",
       "1                            0                               0   \n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "5                            0                               0   \n",
       "...                        ...                             ...   \n",
       "48837                        0                               0   \n",
       "48838                        0                               0   \n",
       "48839                        0                               0   \n",
       "48840                        0                               0   \n",
       "48841                        0                               0   \n",
       "\n",
       "       native-country_United-States  native-country_Vietnam  \\\n",
       "0                                 1                       0   \n",
       "1                                 1                       0   \n",
       "2                                 1                       0   \n",
       "3                                 1                       0   \n",
       "5                                 1                       0   \n",
       "...                             ...                     ...   \n",
       "48837                             1                       0   \n",
       "48838                             1                       0   \n",
       "48839                             1                       0   \n",
       "48840                             1                       0   \n",
       "48841                             1                       0   \n",
       "\n",
       "       native-country_Yugoslavia  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "5                              0  \n",
       "...                          ...  \n",
       "48837                          0  \n",
       "48838                          0  \n",
       "48839                          0  \n",
       "48840                          0  \n",
       "48841                          0  \n",
       "\n",
       "[45222 rows x 105 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_data_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    25, 226802,      7, ...,      1,      0,      0],\n",
       "       [    38,  89814,      9, ...,      1,      0,      0],\n",
       "       [    28, 336951,     12, ...,      1,      0,      0],\n",
       "       ...,\n",
       "       [    58, 151910,      9, ...,      1,      0,      0],\n",
       "       [    22, 201490,      9, ...,      1,      0,      0],\n",
       "       [    52, 287927,      9, ...,      1,      0,      0]], dtype=int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_data_1hot.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_data_1hot = torch.as_tensor(adult_data_1hot.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, ..., 0, 1, 0, 0, 1]\n",
       "Length: 45222\n",
       "Categories (2, int64): [0, 1]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_data_1hot = tf.convert_to_tensor(adult_data_1hot.values)\n",
    "# adult_label = tf.convert_to_tensor(adult_label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Test split\n",
    "train_data, test_data, train_label, test_label = train_test_split(adult_data_1hot, adult_label, test_size  = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalization\n",
    "# from sklearn.preprocessing import StandardScaler  \n",
    "# scaler = StandardScaler()  \n",
    "\n",
    "# # Fitting only on training data\n",
    "# scaler.fit(train_data)  \n",
    "# train_data = scaler.transform(train_data)  \n",
    "\n",
    "# # Applying same transformation to test data\n",
    "# test_data = scaler.transform(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>58</td>\n",
       "      <td>82050</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8296</th>\n",
       "      <td>42</td>\n",
       "      <td>24763</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10796</th>\n",
       "      <td>50</td>\n",
       "      <td>57852</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33890</th>\n",
       "      <td>79</td>\n",
       "      <td>97082</td>\n",
       "      <td>8</td>\n",
       "      <td>18481</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45913</th>\n",
       "      <td>51</td>\n",
       "      <td>230095</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18461</th>\n",
       "      <td>36</td>\n",
       "      <td>393673</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32138</th>\n",
       "      <td>68</td>\n",
       "      <td>211584</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38809</th>\n",
       "      <td>30</td>\n",
       "      <td>329425</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40418</th>\n",
       "      <td>48</td>\n",
       "      <td>273402</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18995</th>\n",
       "      <td>24</td>\n",
       "      <td>265567</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33916 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  educational-num  capital-gain  capital-loss  \\\n",
       "3805    58   82050               10             0             0   \n",
       "8296    42   24763               13             0             0   \n",
       "10796   50   57852               16             0             0   \n",
       "33890   79   97082                8         18481             0   \n",
       "45913   51  230095               11             0             0   \n",
       "...    ...     ...              ...           ...           ...   \n",
       "18461   36  393673               12             0             0   \n",
       "32138   68  211584               10             0             0   \n",
       "38809   30  329425                9             0             0   \n",
       "40418   48  273402                4             0          1902   \n",
       "18995   24  265567                7             0             0   \n",
       "\n",
       "       hours-per-week  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "3805               60                      0                    0   \n",
       "8296               65                      0                    0   \n",
       "10796              55                      0                    0   \n",
       "33890              45                      0                    0   \n",
       "45913              40                      0                    0   \n",
       "...               ...                    ...                  ...   \n",
       "18461              50                      0                    0   \n",
       "32138              40                      0                    0   \n",
       "38809              40                      0                    0   \n",
       "40418              40                      0                    1   \n",
       "18995              35                      0                    0   \n",
       "\n",
       "       workclass_Never-worked  workclass_Private  ...  \\\n",
       "3805                        0                  1  ...   \n",
       "8296                        0                  0  ...   \n",
       "10796                       0                  1  ...   \n",
       "33890                       0                  0  ...   \n",
       "45913                       0                  0  ...   \n",
       "...                       ...                ...  ...   \n",
       "18461                       0                  1  ...   \n",
       "32138                       0                  0  ...   \n",
       "38809                       0                  1  ...   \n",
       "40418                       0                  0  ...   \n",
       "18995                       0                  1  ...   \n",
       "\n",
       "       native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "3805                         0                           0   \n",
       "8296                         0                           0   \n",
       "10796                        0                           0   \n",
       "33890                        0                           0   \n",
       "45913                        0                           0   \n",
       "...                        ...                         ...   \n",
       "18461                        0                           0   \n",
       "32138                        0                           0   \n",
       "38809                        0                           0   \n",
       "40418                        0                           0   \n",
       "18995                        0                           0   \n",
       "\n",
       "       native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "3805                         0                     0                      0   \n",
       "8296                         0                     0                      0   \n",
       "10796                        0                     0                      0   \n",
       "33890                        0                     0                      0   \n",
       "45913                        0                     0                      0   \n",
       "...                        ...                   ...                    ...   \n",
       "18461                        0                     0                      0   \n",
       "32138                        0                     0                      0   \n",
       "38809                        0                     0                      0   \n",
       "40418                        0                     0                      0   \n",
       "18995                        0                     0                      0   \n",
       "\n",
       "       native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "3805                         0                               0   \n",
       "8296                         0                               0   \n",
       "10796                        0                               0   \n",
       "33890                        0                               0   \n",
       "45913                        0                               0   \n",
       "...                        ...                             ...   \n",
       "18461                        0                               0   \n",
       "32138                        0                               0   \n",
       "38809                        0                               0   \n",
       "40418                        0                               0   \n",
       "18995                        0                               0   \n",
       "\n",
       "       native-country_United-States  native-country_Vietnam  \\\n",
       "3805                              1                       0   \n",
       "8296                              1                       0   \n",
       "10796                             1                       0   \n",
       "33890                             1                       0   \n",
       "45913                             1                       0   \n",
       "...                             ...                     ...   \n",
       "18461                             1                       0   \n",
       "32138                             1                       0   \n",
       "38809                             1                       0   \n",
       "40418                             1                       0   \n",
       "18995                             1                       0   \n",
       "\n",
       "       native-country_Yugoslavia  \n",
       "3805                           0  \n",
       "8296                           0  \n",
       "10796                          0  \n",
       "33890                          0  \n",
       "45913                          0  \n",
       "...                          ...  \n",
       "18461                          0  \n",
       "32138                          0  \n",
       "38809                          0  \n",
       "40418                          0  \n",
       "18995                          0  \n",
       "\n",
       "[33916 rows x 105 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3805     1\n",
       "8296     0\n",
       "10796    1\n",
       "33890    1\n",
       "45913    0\n",
       "        ..\n",
       "18461    1\n",
       "32138    1\n",
       "38809    0\n",
       "40418    0\n",
       "18995    0\n",
       "Name: income, Length: 33916, dtype: category\n",
       "Categories (2, int64): [0, 1]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(actual, pred):\n",
    "    \n",
    "    confusion = pd.crosstab(actual, pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    TP = confusion.loc['>50K','>50K']\n",
    "    TN = confusion.loc['<=50K','<=50K']\n",
    "    FP = confusion.loc['<=50K','>50K']\n",
    "    FN = confusion.loc['>50K','<=50K']\n",
    "\n",
    "    accuracy = ((TP+TN))/(TP+FN+FP+TN)\n",
    "    precision = (TP)/(TP+FP)\n",
    "    recall = (TP)/(TP+FN)\n",
    "    f_measure = (2*recall*precision)/(recall+precision)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    error_rate = 1 - accuracy\n",
    "    \n",
    "    out = {}\n",
    "    out['accuracy'] =  accuracy\n",
    "    out['precision'] = precision\n",
    "    out['recall'] = recall\n",
    "    out['f_measure'] = f_measure\n",
    "    out['sensitivity'] = sensitivity\n",
    "    out['specificity'] = specificity\n",
    "    out['error_rate'] = error_rate\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yang - DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import MaxNorm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, test_data, train_label, test_label\n",
    "train_data = tf.convert_to_tensor(train_data)\n",
    "train_label = tf.convert_to_tensor(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(33916, 105), dtype=int64, numpy=\n",
       "array([[    58,  82050,     10, ...,      1,      0,      0],\n",
       "       [    42,  24763,     13, ...,      1,      0,      0],\n",
       "       [    50,  57852,     16, ...,      1,      0,      0],\n",
       "       ...,\n",
       "       [    30, 329425,      9, ...,      1,      0,      0],\n",
       "       [    48, 273402,      4, ...,      1,      0,      0],\n",
       "       [    24, 265567,      7, ...,      1,      0,      0]], dtype=int64)>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5442 - accuracy: 0.7779\n",
      "Epoch 2/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5104 - accuracy: 0.7869\n",
      "Epoch 3/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5074 - accuracy: 0.7882\n",
      "Epoch 4/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5042 - accuracy: 0.7911\n",
      "Epoch 5/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5021 - accuracy: 0.7905\n",
      "Epoch 6/30\n",
      "3392/3392 [==============================] - 4s 1ms/step - loss: 0.5025 - accuracy: 0.7900\n",
      "Epoch 7/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5017 - accuracy: 0.7912\n",
      "Epoch 8/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5029 - accuracy: 0.7905\n",
      "Epoch 9/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5025 - accuracy: 0.7898\n",
      "Epoch 10/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5010 - accuracy: 0.7915\n",
      "Epoch 11/30\n",
      "3392/3392 [==============================] - 4s 1ms/step - loss: 0.5010 - accuracy: 0.7923\n",
      "Epoch 12/30\n",
      "3392/3392 [==============================] - 4s 1ms/step - loss: 0.5006 - accuracy: 0.7917\n",
      "Epoch 13/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5033 - accuracy: 0.7905\n",
      "Epoch 14/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5015 - accuracy: 0.7916\n",
      "Epoch 15/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5050 - accuracy: 0.7892\n",
      "Epoch 16/30\n",
      "3392/3392 [==============================] - 5s 2ms/step - loss: 0.5013 - accuracy: 0.7915\n",
      "Epoch 17/30\n",
      "3392/3392 [==============================] - 5s 2ms/step - loss: 0.5037 - accuracy: 0.7905\n",
      "Epoch 18/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.4996 - accuracy: 0.7926\n",
      "Epoch 19/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5003 - accuracy: 0.7922\n",
      "Epoch 20/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5011 - accuracy: 0.7926\n",
      "Epoch 21/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5013 - accuracy: 0.7906\n",
      "Epoch 22/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5038 - accuracy: 0.7902\n",
      "Epoch 23/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5015 - accuracy: 0.7920\n",
      "Epoch 24/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5013 - accuracy: 0.7922\n",
      "Epoch 25/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5012 - accuracy: 0.7923\n",
      "Epoch 26/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5033 - accuracy: 0.7911\n",
      "Epoch 27/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5033 - accuracy: 0.7905\n",
      "Epoch 28/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5037 - accuracy: 0.7912\n",
      "Epoch 29/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5059 - accuracy: 0.7882\n",
      "Epoch 30/30\n",
      "3392/3392 [==============================] - 5s 1ms/step - loss: 0.5052 - accuracy: 0.7885\n",
      "354/354 [==============================] - 0s 951us/step - loss: 0.5043 - accuracy: 0.7881\n",
      "accuracy: 78.81%\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=105, activation='relu', kernel_initializer=\"uniform\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(30, activation='relu', kernel_constraint=MaxNorm(3), kernel_initializer=\"uniform\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='relu', kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_data, train_label, epochs=30, batch_size=10)\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(test_data, test_label)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Model Development\n",
    "### 4.2.1. Decision Tree\n",
    "\n",
    "For the decision tree classifier, I experimented with the splitting criteria, minimum samples required to split, max depth of the tree, minimum samples required at the leaf level and the maximum features to consider when looking for the best split. The following values of the parameters attained the best accuracy during classification. Results in the table below.\n",
    "\n",
    "*\t**Splitting criteria:** Gini Index (Using Gini Index marginally outperformed Entropy with a higher accuracy.)\n",
    "*\t**Min samples required to split:** 5% (Best amongst 1%, 10% and 5%.)\n",
    "*\t**Max Depth:** None\n",
    "*\t**Min samples required at leaf:**  0.1 % (Best amongst 1%, 5% and 0.1%.)\n",
    "*\t**Max features:** number of features (Performs better than 'auto', 'log2' and 'sqrt'.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desicion Tree using Gini Index : 85.14 percent.\n",
      "Desicion Tree using Entropy : 85.27 percent.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_measure</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>error_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DTree_Entropy</th>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.7654</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.6580</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.9424</td>\n",
       "      <td>0.1473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTree_Gini</th>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.7592</td>\n",
       "      <td>0.5782</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.5782</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>0.1486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  precision  recall  f_measure  sensitivity  \\\n",
       "DTree_Entropy    0.8527     0.7654  0.5771     0.6580       0.5771   \n",
       "DTree_Gini       0.8514     0.7592  0.5782     0.6564       0.5782   \n",
       "\n",
       "               specificity  error_rate  \n",
       "DTree_Entropy       0.9424      0.1473  \n",
       "DTree_Gini          0.9403      0.1486  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#printmd('### 3.1.1. Model Development ')\n",
    "\n",
    "# Gini \n",
    "clf_gini = tree.DecisionTreeClassifier(criterion = 'gini', min_samples_split = 0.05, min_samples_leaf = 0.001, max_features = None)\n",
    "clf_gini = clf_gini.fit(train_data, train_label)\n",
    "clf_gini_pred = clf_gini.predict(test_data)\n",
    "DTree_Gini = model_eval(test_label, clf_gini_pred)\n",
    "print('Desicion Tree using Gini Index : %.2f percent.' % (round(DTree_Gini['accuracy']*100,2)))\n",
    "\n",
    "\n",
    "# Entropy\n",
    "clf_entropy = tree.DecisionTreeClassifier(criterion = 'entropy', min_samples_split = 0.05, min_samples_leaf = 0.001)\n",
    "clf_entropy = clf_entropy.fit(train_data, train_label)\n",
    "clf_entropy_pred = clf_entropy.predict(test_data)\n",
    "DTree_Entropy = model_eval(test_label, clf_entropy_pred)\n",
    "print('Desicion Tree using Entropy : %.2f percent.' % (round(DTree_Entropy['accuracy']*100,2)))\n",
    "\n",
    "\n",
    "#printmd('### 3.1.2. Model Evaulation ')\n",
    "ovl_dtree = round(pd.DataFrame([DTree_Entropy, DTree_Gini], index = ['DTree_Entropy','DTree_Gini']),4)\n",
    "display(ovl_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tree\n",
    "\n",
    "# from sklearn.tree import export_graphviz\n",
    "# from IPython.display import SVG\n",
    "# from graphviz import Source\n",
    "\n",
    "\n",
    "\n",
    "# graph = Source( tree.export_graphviz(clf, out_file=None, feature_names=train_data.columns))\n",
    "\n",
    "# # Display Tree\n",
    "# SVG(graph.pipe(format='svg'))\n",
    "\n",
    "# # Save Tree as PNG\n",
    "# png_bytes = graph.pipe(format='png')\n",
    "# with open('dtree_pipe.png','wb') as f:\n",
    "#     f.write(png_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Artificial Neural Network\n",
    "For the ANN classifier, I experimented with the activation function, the solver for weight optimization, regularization term and learning schedule for weight updates. The following values of the parameters attained the best accuracy during classification. Other parameters were neither applicable to the 'adam' solver nor did it improve the performance of the model. Results in the table below.\n",
    "\n",
    "*\t**Activation:** Logistic (Marginally outperformed 'relu', 'tanh' and 'identity' functions.)\n",
    "*   **Solver:** Adam (Works well on relatively large datasets with thousands of training samples or more)\n",
    "*   **Alpha:** 1e-4 (Best amongst 1, 1e-1, 1e-2, 1e-3, 1e-4 and 1e-5)\n",
    "*   **Learning Rate:**  'invscaling' (Gradually decreases the learning rate at each time step 't' using an inverse scaling exponent of 'power_t'.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN using TanH and lbfgs solver : 84.82 percent.\n",
      "ANN using relu and adam solver : 85.13 percent.\n",
      "ANN using logistic and adam solver : 85.09 percent.\n",
      "ANN using identity and adam solver : 85.18 percent.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_measure</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>error_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANN_TanH</th>\n",
       "      <td>0.8482</td>\n",
       "      <td>0.7318</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.1518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANN_relu</th>\n",
       "      <td>0.8513</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>0.9291</td>\n",
       "      <td>0.1487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANN_log</th>\n",
       "      <td>0.8509</td>\n",
       "      <td>0.7370</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>0.6678</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>0.9291</td>\n",
       "      <td>0.1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANN_identity</th>\n",
       "      <td>0.8518</td>\n",
       "      <td>0.7468</td>\n",
       "      <td>0.6001</td>\n",
       "      <td>0.6655</td>\n",
       "      <td>0.6001</td>\n",
       "      <td>0.9338</td>\n",
       "      <td>0.1482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  precision  recall  f_measure  sensitivity  \\\n",
       "ANN_TanH        0.8482     0.7318  0.6027     0.6610       0.6027   \n",
       "ANN_relu        0.8513     0.7375  0.6124     0.6692       0.6124   \n",
       "ANN_log         0.8509     0.7370  0.6106     0.6678       0.6106   \n",
       "ANN_identity    0.8518     0.7468  0.6001     0.6655       0.6001   \n",
       "\n",
       "              specificity  error_rate  \n",
       "ANN_TanH           0.9281      0.1518  \n",
       "ANN_relu           0.9291      0.1487  \n",
       "ANN_log            0.9291      0.1491  \n",
       "ANN_identity       0.9338      0.1482  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tan H\n",
    "ann_tanh = MLPClassifier(activation = 'tanh', solver='lbfgs', alpha=1e-1, hidden_layer_sizes=(10, 2), random_state=1, warm_start=True)\n",
    "ann_tanh.fit(train_data, train_label)                         \n",
    "ann_tanh_pred = ann_tanh.predict(test_data)\n",
    "ANN_TanH = model_eval(test_label, ann_tanh_pred)\n",
    "print('ANN using TanH and lbfgs solver : %.2f percent.' % (round(ANN_TanH['accuracy']*100,2)))\n",
    "\n",
    "\n",
    "# Relu\n",
    "ann_relu = MLPClassifier(activation = 'relu', solver='adam', alpha=1e-1, \n",
    "                    hidden_layer_sizes=(5, 2), random_state=1,\n",
    "                    learning_rate  = 'invscaling',\n",
    "                    warm_start = True)\n",
    "ann_relu.fit(train_data, train_label)                         \n",
    "ann_relu_pred = ann_relu.predict(test_data)\n",
    "ANN_relu = model_eval(test_label, ann_relu_pred)\n",
    "print('ANN using relu and adam solver : %.2f percent.' % (round(ANN_relu['accuracy']*100,2)))\n",
    "\n",
    "# Log\n",
    "ann_log = MLPClassifier(activation = 'logistic', solver='adam', \n",
    "                    alpha=1e-4, hidden_layer_sizes=(5, 2),\n",
    "                    learning_rate  = 'invscaling', \n",
    "                    random_state=1, warm_start = True)\n",
    "ann_log.fit(train_data, train_label)                         \n",
    "ann_log_pred = ann_log.predict(test_data)\n",
    "ANN_log = model_eval(test_label, ann_log_pred)\n",
    "print('ANN using logistic and adam solver : %.2f percent.' % (round(ANN_log['accuracy']*100,2)))\n",
    "\n",
    "# Identity\n",
    "ann_identity = MLPClassifier(activation = 'identity', solver='adam', alpha=1e-1, hidden_layer_sizes=(5, 2), random_state=1, warm_start = True)\n",
    "ann_identity.fit(train_data, train_label)                         \n",
    "ann_identity_pred = ann_identity.predict(test_data)\n",
    "ANN_identity = model_eval(test_label, ann_identity_pred)\n",
    "print('ANN using identity and adam solver : %.2f percent.' % (round(ANN_identity['accuracy']*100,2)))\n",
    "\n",
    "#printmd('### 3.2.2. Model Evaulation ')\n",
    "ovl_ann = round(pd.DataFrame([ANN_TanH, ANN_relu, ANN_log, ANN_identity], index = ['ANN_TanH','ANN_relu', 'ANN_log', 'ANN_identity']),4)\n",
    "display(ovl_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. Support Vector Machine\n",
    "For the SVM classifier, I experimented with the various available kernels, the penalty of the error term and the tolerance for stopping criteria. The following values of the parameters attained the best accuracy during classification. Results in the table below.\n",
    "\n",
    "*\t**Kernel:** rbf (Marginally outperformed 'linear, 'poly' and 'sigmoid' kernels.)\n",
    "*\t**C, penalty of the error term:** 1 (Best amongst 0.1, 0.5, 1 and 10)\n",
    "*\t**Tolerance for stopping criteria:** 1e-3 (Best amongst 1e-1, 1e-2, 1e-3, 1e-4 and 1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM using rbf kernel : 84.96 percent.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Linear kernel\u001b[39;00m\n\u001b[0;32m      9\u001b[0m svm_clf_linear \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[43msvm_clf_linear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m svm_clf_linear_pred \u001b[38;5;241m=\u001b[39m svm_clf_linear\u001b[38;5;241m.\u001b[39mpredict(test_data)\n\u001b[0;32m     12\u001b[0m SVM_linear \u001b[38;5;241m=\u001b[39m model_eval(test_label, svm_clf_linear_pred)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# rbf kernal\n",
    "svm_clf_rbf = svm.SVC(kernel = 'rbf', C = 1, tol = 1e-3)\n",
    "svm_clf_rbf.fit(train_data, train_label)\n",
    "svm_clf_rbf_pred = svm_clf_rbf.predict(test_data)\n",
    "SVM_rbf = model_eval(test_label, svm_clf_rbf_pred)\n",
    "print('SVM using rbf kernel : %.2f percent.' % (round(SVM_rbf['accuracy']*100,2)))\n",
    "\n",
    "# Linear kernel\n",
    "svm_clf_linear = svm.SVC(kernel = 'linear')\n",
    "svm_clf_linear.fit(train_data, train_label)\n",
    "svm_clf_linear_pred = svm_clf_linear.predict(test_data)\n",
    "SVM_linear = model_eval(test_label, svm_clf_linear_pred)\n",
    "print('SVM using linear kernel : %.2f percent.' % (round(SVM_linear['accuracy']*100,2)))\n",
    "\n",
    "\n",
    "# Poly kernal\n",
    "svm_clf_poly = svm.SVC(kernel = 'poly')\n",
    "svm_clf_poly.fit(train_data, train_label)\n",
    "svm_clf_poly_pred = svm_clf_poly.predict(test_data)\n",
    "SVM_poly = model_eval(test_label, svm_clf_poly_pred)\n",
    "print('SVM using poly kernel : %.2f percent.' % (round(SVM_poly['accuracy']*100,2)))\n",
    "\n",
    "\n",
    "svm_clf_sigmoid = svm.SVC(kernel = 'sigmoid')\n",
    "svm_clf_sigmoid.fit(train_data, train_label)\n",
    "svm_clf_sigmoid_pred = svm_clf_sigmoid.predict(test_data)\n",
    "SVM_sigmoid = model_eval(test_label, svm_clf_sigmoid_pred)\n",
    "print('SVM using sigmoid kernel : %.2f percent.' % (round(SVM_sigmoid['accuracy']*100,2)))\n",
    "\n",
    "\n",
    "\n",
    "#printmd('### 3.3.2. Model Evaulation ')\n",
    "ovl_svm = round(pd.DataFrame([SVM_rbf, SVM_linear, SVM_poly, SVM_sigmoid], index = ['SVM_rbf','SVM_linear', 'SVM_poly', 'SVM_sigmoid']),4)\n",
    "display(ovl_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4. Ensemble Models\n",
    "\n",
    "### 4.2.4.1. Random Forest\n",
    "For the random forests classifier, I experimented with the number of trees, splitting criteria, minimum samples required to split, max depth of the tree, minimum samples required at the leaf level and the maximum features to consider when looking for the best split. The following values of the parameters attained the best accuracy during classification. Results in the table below.\n",
    "\n",
    "*\t**Num estimators:** 100 (Best amongst 10, 50 and 100)\n",
    "*\t**Splitting criteria:** Gini Index (Using Gini Index marginally outperformed Entropy with a higher accuracy.)\n",
    "*\t**Min samples required to split:** 5% (Best amongst 1%, 10% and 5%.)\n",
    "*\t**Max Depth:** None\n",
    "*\t**Min samples required at leaf:**  0.1 % (Best amongst 1%, 5% and 0.1%.)\n",
    "*\t**Max features:** number of features (Performs better than 'auto', 'log2' and 'sqrt'.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini\n",
    "r_forest_gini = RandomForestClassifier(n_estimators=100, criterion = 'gini', max_features = None,  min_samples_split = 0.05, min_samples_leaf = 0.001)\n",
    "r_forest_gini.fit(train_data, train_label)\n",
    "r_forest_gini_pred = r_forest_gini.predict(test_data)\n",
    "rforest_gini = model_eval(test_label, r_forest_gini_pred)\n",
    "print('Random Forest using Gini Index : %.2f percent.' % (round(rforest_gini['accuracy']*100,2)))\n",
    "\n",
    "# Entropy\n",
    "r_forest_entropy = RandomForestClassifier(n_estimators=100, criterion = 'entropy', max_features = None,  min_samples_split = 0.05, min_samples_leaf = 0.001)\n",
    "r_forest_entropy.fit(train_data, train_label)\n",
    "r_forest_entropy_pred = r_forest_entropy.predict(test_data)\n",
    "rforest_entropy = model_eval(test_label, r_forest_entropy_pred)\n",
    "print('Random Forest using Entropy : %.2f percent.' % (round(rforest_entropy['accuracy']*100,2)))\n",
    "\n",
    "#printmd('### 3.4.1.2. Model Evaulation ')\n",
    "ovl_rf = round(pd.DataFrame([rforest_gini, rforest_entropy], index = ['rforest_gini','rforest_entropy']),4)\n",
    "display(ovl_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4.2. Adaboost\n",
    "For the adaboost classifier, I experimented with base estimator from which the boosted ensemble is built and number of estimators. The following values of the parameters attained the best accuracy during classification. Results in the table below.\n",
    "\n",
    "*\t**Base Estimator:** DecisionTreeClassifier\n",
    "*\t**Num estimators:** 100 (Best amongst 10, 50 and 100.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=100)                     \n",
    "ada.fit(train_data, train_label)\n",
    "ada_pred = ada.predict(test_data)\n",
    "adaboost = model_eval(test_label, ada_pred)\n",
    "print('Adaboost : %.2f percent.' % (round(adaboost['accuracy']*100,2)))\n",
    "\n",
    "#printmd('### 3.4.2.2. Model Evaulation ')\n",
    "ovl_ada = round(pd.DataFrame([adaboost], index = ['adaboost']),4)\n",
    "display(ovl_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty = 'l2', dual = False, tol = 1e-4, fit_intercept = True, \n",
    "                            solver = 'liblinear')\n",
    "log_reg.fit(train_data, train_label)\n",
    "log_reg_pred = log_reg.predict(test_data)\n",
    "logistic_reg = model_eval(test_label, log_reg_pred)\n",
    "print('Logistic Regression : %.2f percent.' % (round(logistic_reg['accuracy']*100,3)))\n",
    "\n",
    "#printmd('### 3.5.2. Model Evaulation ')\n",
    "ovl_logreg = round(pd.DataFrame([logistic_reg], index = ['logistic_reg']),4)\n",
    "display(ovl_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.6. k Nearest Neighbours\n",
    "For the K nearest neighbours classifier, I experimented with the num of neighbours values, every odd number ranging from 1 to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_outs = []\n",
    "for i in range(1,50,2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(train_data, train_label) \n",
    "    knn_pred = knn.predict(test_data)\n",
    "    knn_perf = model_eval(test_label, knn_pred)\n",
    "    knn_perf['k'] = i\n",
    "    knn_outs.append(knn_perf)\n",
    "\n",
    "ovl_knn = round(pd.DataFrame(knn_outs),4)\n",
    "display(ovl_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Model Evaluation\n",
    "## 5.1. Overall Performance Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_eval = pd.concat([ovl_dtree, ovl_ann, ovl_svm, ovl_rf, ovl_ada, ovl_logreg], axis = 0)\n",
    "overall_eval.sort_values(by = ['f_measure', 'accuracy'], ascending = False, inplace = True)\n",
    "\n",
    "printmd('Combing the performance statistics of all the model developed, as seen in table below, \\\n",
    "        we see that the ensemble model Adaboost hast the highest F-measure (0.6833), precision (0.7812) \\\n",
    "        and accuracy (0.8647). The Artificial neural network models are only marginally being in terms of \\\n",
    "        accuracy and F-measure. Almost all the model have an accuracy greater than 0.84, expect for two SVM \\\n",
    "        models. The table below lists the accuracy, error rate, F-measure, precision, recall, sensitivity and \\\n",
    "        specificity of all the models developed.')\n",
    "\n",
    "display(overall_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRoc(test_data, test_label, classifiers, pred_labels, plot_labels, limiter):\n",
    "    \n",
    "    color = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "    \n",
    "    y_test = label_binarize(test_label, classes=['<=50K', '>50K'])\n",
    "    plt.figure()\n",
    "    \n",
    "    for i in range(len(classifiers)):\n",
    "        \n",
    "        if plot_labels[i] not in limiter:\n",
    "            continue\n",
    "        \n",
    "        y_score = classifiers[i].predict_proba(test_data)\n",
    "        pos_class_index = list(np.unique(pred_labels[i])).index('>50K')\n",
    "        \n",
    "        fpr, tpr, thres = metrics.roc_curve(y_test.ravel(),y_score[:,pos_class_index], pos_label=1)\n",
    "                               \n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color=color[i % len(color)],lw=lw, label=plot_labels[i])\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "classifier_list = [clf_gini\n",
    "                ,clf_entropy\n",
    "                ,ann_tanh\n",
    "                ,ann_relu\n",
    "                ,ann_log\n",
    "                ,ann_identity\n",
    "#                 ,svm_clf_rbf\n",
    "#                 ,svm_clf_linear\n",
    "#                 ,svm_clf_poly\n",
    "#                 ,svm_clf_sigmoid\n",
    "                ,r_forest_gini\n",
    "                ,r_forest_entropy\n",
    "                ,ada\n",
    "                ,log_reg\n",
    "                ] \n",
    "pred_list = [clf_gini_pred\n",
    "            ,clf_entropy_pred\n",
    "            ,ann_tanh_pred\n",
    "            ,ann_relu_pred\n",
    "            ,ann_log_pred\n",
    "            ,ann_identity_pred\n",
    "#             ,svm_clf_rbf_pred\n",
    "#             ,svm_clf_linear_pred\n",
    "#             ,svm_clf_poly_pred\n",
    "#             ,svm_clf_sigmoid_pred\n",
    "            ,r_forest_gini_pred\n",
    "            ,r_forest_entropy_pred\n",
    "            ,ada_pred\n",
    "            ,log_reg_pred\n",
    "            ]\n",
    "\n",
    "clf_labels = ['DTree Gini'\n",
    "            ,'DTree Entropy'\n",
    "            ,'ANN TanH'\n",
    "            ,'ANN relu'\n",
    "            ,'ANN Logistic'\n",
    "            ,'ANN Identity'\n",
    "#             ,svm_clf_rbf_pred\n",
    "#             ,svm_clf_linear_pred\n",
    "#             ,svm_clf_poly_pred\n",
    "#             ,svm_clf_sigmoid_pred\n",
    "            ,'RForest Gini'\n",
    "            ,'RForest Entropy'\n",
    "            ,'Adaboost'\n",
    "            ,'Logistic Regression'\n",
    "            ]\n",
    "\n",
    "limiter = ['Adaboost', 'ANN TanH', 'ANN relu', 'ANN Logistic', 'Logistic Regression']\n",
    "generateRoc(test_data, test_label, classifier_list, pred_list, clf_labels, limiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above of the receiver operating characteristic curve for the top 5 models; Adaboost, ANN with logistics activation function, ANN with relu activation function, ANN with tanH activation function and logistic regression model. I chose to plot only the top 5 models as the ROC curves of most of the models overlap and the it is not easy to interpret the curve. \n",
    "\n",
    "From figure, we can see that the ROC curve of the Adaboost model has the highest lift and is closest to the top left corner (TPR of 1 and FPR of 0) of the plot. The Adaboost model's curve clearly separates itself from the ROC curves of the other 4 models, which overlap with each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose **Adaboost** model as my preferred my approach. The Adaboost model not only has the **highest accuracy**, but also has the **highest precision and F-measure** of all the models developed as a part of this analysis. The advantages of using Adaboost over other models is that they are very simple to implement. Since they are made up of weak individual learners, they are less susceptible to overfitting. However, Adaboost is sensitive to noisy data and outliers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
